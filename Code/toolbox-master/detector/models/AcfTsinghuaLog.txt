---------------------------------------------------------------------------
Training stage 0
Sampled 16740 windows from 10121 images.
Done sampling windows (time=1203s).
Computing lambdas... done (time=39s).
Extracting features... done (time=9s).
Sampled 10000 windows from 448 images.
Done sampling windows (time=36s).
Extracting features... done (time=3s).
Training AdaBoost: nWeak= 32 nFtrs=1920 pos=33480 neg=10000
 i=  16 alpha=0.559 err=0.246 loss=1.49e-02
 i=  32 alpha=0.543 err=0.252 loss=1.61e-03
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=1.1s).
Done training stage 0 (time=1291s).
---------------------------------------------------------------------------
Training stage 1
Sampled 10000 windows from 448 images.
Done sampling windows (time=54s).
Extracting features... done (time=3s).
Training AdaBoost: nWeak=128 nFtrs=1920 pos=33480 neg=20000
 i=  16 alpha=0.321 err=0.345 loss=2.33e-01
 i=  32 alpha=0.263 err=0.372 loss=1.24e-01
 i=  48 alpha=0.258 err=0.374 loss=7.94e-02
 i=  64 alpha=0.187 err=0.408 loss=5.33e-02
 i=  80 alpha=0.214 err=0.395 loss=3.77e-02
 i=  96 alpha=0.202 err=0.400 loss=2.67e-02
 i= 112 alpha=0.191 err=0.406 loss=1.95e-02
 i= 128 alpha=0.184 err=0.409 loss=1.41e-02
Done training err=0.0014 fp=0.0008 fn=0.0021 (t=2.6s).
Done training stage 1 (time=59s).
---------------------------------------------------------------------------
Training stage 2
Sampled 10000 windows from 448 images.
Done sampling windows (time=45s).
Extracting features... done (time=3s).
Training AdaBoost: nWeak=512 nFtrs=1920 pos=33480 neg=30000
 i=  16 alpha=0.266 err=0.370 loss=2.99e-01
 i=  32 alpha=0.215 err=0.394 loss=1.81e-01
 i=  48 alpha=0.201 err=0.401 loss=1.26e-01
 i=  64 alpha=0.176 err=0.413 loss=9.10e-02
 i=  80 alpha=0.198 err=0.402 loss=6.72e-02
 i=  96 alpha=0.173 err=0.414 loss=5.10e-02
 i= 112 alpha=0.158 err=0.422 loss=3.92e-02
 i= 128 alpha=0.189 err=0.407 loss=3.06e-02
 i= 144 alpha=0.182 err=0.410 loss=2.40e-02
 i= 160 alpha=0.166 err=0.418 loss=1.92e-02
 i= 176 alpha=0.177 err=0.412 loss=1.54e-02
 i= 192 alpha=0.167 err=0.417 loss=1.25e-02
 i= 208 alpha=0.164 err=0.419 loss=1.02e-02
 i= 224 alpha=0.163 err=0.419 loss=8.25e-03
 i= 240 alpha=0.163 err=0.419 loss=6.65e-03
 i= 256 alpha=0.167 err=0.417 loss=5.33e-03
 i= 272 alpha=0.164 err=0.419 loss=4.31e-03
 i= 288 alpha=0.152 err=0.425 loss=3.56e-03
 i= 304 alpha=0.156 err=0.422 loss=2.94e-03
 i= 320 alpha=0.133 err=0.434 loss=2.43e-03
 i= 336 alpha=0.161 err=0.420 loss=1.98e-03
 i= 352 alpha=0.149 err=0.426 loss=1.64e-03
 i= 368 alpha=0.170 err=0.416 loss=1.34e-03
 i= 384 alpha=0.169 err=0.416 loss=1.11e-03
 i= 400 alpha=0.161 err=0.420 loss=9.08e-04
 i= 416 alpha=0.163 err=0.419 loss=7.36e-04
 i= 432 alpha=0.133 err=0.434 loss=6.11e-04
 i= 448 alpha=0.140 err=0.431 loss=5.05e-04
 i= 464 alpha=0.142 err=0.429 loss=4.22e-04
 i= 480 alpha=0.166 err=0.418 loss=3.43e-04
 i= 496 alpha=0.159 err=0.421 loss=2.88e-04
 i= 512 alpha=0.156 err=0.422 loss=2.37e-04
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=10.9s).
Done training stage 2 (time=59s).
---------------------------------------------------------------------------
Training stage 3
Sampled 3897 windows from 1000 images.
Done sampling windows (time=91s).
Extracting features... done (time=1s).
Training AdaBoost: nWeak=2048 nFtrs=1920 pos=33480 neg=30000
 i=  16 alpha=0.260 err=0.373 loss=3.19e-01
 i=  32 alpha=0.199 err=0.402 loss=2.15e-01
 i=  48 alpha=0.186 err=0.408 loss=1.60e-01
 i=  64 alpha=0.173 err=0.414 loss=1.26e-01
 i=  80 alpha=0.183 err=0.409 loss=1.00e-01
 i=  96 alpha=0.170 err=0.416 loss=8.11e-02
 i= 112 alpha=0.149 err=0.426 loss=6.55e-02
 i= 128 alpha=0.156 err=0.423 loss=5.38e-02
 i= 144 alpha=0.141 err=0.430 loss=4.44e-02
 i= 160 alpha=0.144 err=0.429 loss=3.66e-02
 i= 176 alpha=0.152 err=0.425 loss=3.05e-02
 i= 192 alpha=0.155 err=0.423 loss=2.55e-02
 i= 208 alpha=0.171 err=0.415 loss=2.15e-02
 i= 224 alpha=0.151 err=0.425 loss=1.82e-02
 i= 240 alpha=0.144 err=0.428 loss=1.54e-02
 i= 256 alpha=0.124 err=0.438 loss=1.30e-02
 i= 272 alpha=0.146 err=0.428 loss=1.09e-02
 i= 288 alpha=0.145 err=0.428 loss=9.20e-03
 i= 304 alpha=0.137 err=0.432 loss=7.80e-03
 i= 320 alpha=0.146 err=0.428 loss=6.71e-03
 i= 336 alpha=0.132 err=0.435 loss=5.74e-03
 i= 352 alpha=0.132 err=0.435 loss=4.87e-03
 i= 368 alpha=0.138 err=0.432 loss=4.13e-03
 i= 384 alpha=0.148 err=0.426 loss=3.53e-03
 i= 400 alpha=0.156 err=0.423 loss=2.98e-03
 i= 416 alpha=0.147 err=0.427 loss=2.52e-03
 i= 432 alpha=0.120 err=0.440 loss=2.17e-03
 i= 448 alpha=0.156 err=0.423 loss=1.83e-03
 i= 464 alpha=0.147 err=0.427 loss=1.55e-03
 i= 480 alpha=0.157 err=0.422 loss=1.32e-03
 i= 496 alpha=0.141 err=0.430 loss=1.15e-03
 i= 512 alpha=0.131 err=0.435 loss=9.83e-04
 i= 528 alpha=0.154 err=0.424 loss=8.37e-04
 i= 544 alpha=0.143 err=0.429 loss=7.09e-04
 i= 560 alpha=0.148 err=0.427 loss=6.09e-04
 i= 576 alpha=0.144 err=0.428 loss=5.24e-04
 i= 592 alpha=0.138 err=0.432 loss=4.58e-04
 i= 608 alpha=0.138 err=0.431 loss=3.91e-04
 i= 624 alpha=0.145 err=0.428 loss=3.32e-04
 i= 640 alpha=0.158 err=0.422 loss=2.85e-04
 i= 656 alpha=0.131 err=0.435 loss=2.48e-04
 i= 672 alpha=0.150 err=0.425 loss=2.13e-04
 i= 688 alpha=0.126 err=0.438 loss=1.85e-04
 i= 704 alpha=0.135 err=0.433 loss=1.59e-04
 i= 720 alpha=0.133 err=0.434 loss=1.37e-04
 i= 736 alpha=0.141 err=0.430 loss=1.18e-04
 i= 752 alpha=0.152 err=0.425 loss=1.01e-04
 i= 768 alpha=0.137 err=0.432 loss=8.68e-05
 i= 784 alpha=0.147 err=0.427 loss=7.49e-05
 i= 800 alpha=0.140 err=0.431 loss=6.42e-05
 i= 816 alpha=0.145 err=0.428 loss=5.56e-05
 i= 832 alpha=0.132 err=0.434 loss=4.78e-05
 i= 848 alpha=0.121 err=0.440 loss=4.09e-05
 i= 864 alpha=0.141 err=0.430 loss=3.51e-05
 i= 880 alpha=0.144 err=0.429 loss=3.00e-05
 i= 896 alpha=0.132 err=0.434 loss=2.56e-05
 i= 912 alpha=0.145 err=0.428 loss=2.17e-05
 i= 928 alpha=0.134 err=0.433 loss=1.86e-05
 i= 944 alpha=0.127 err=0.437 loss=1.61e-05
 i= 960 alpha=0.136 err=0.433 loss=1.39e-05
 i= 976 alpha=0.149 err=0.426 loss=1.19e-05
 i= 992 alpha=0.144 err=0.428 loss=1.02e-05
 i=1008 alpha=0.137 err=0.432 loss=8.83e-06
 i=1024 alpha=0.151 err=0.425 loss=7.63e-06
 i=1040 alpha=0.139 err=0.431 loss=6.50e-06
 i=1056 alpha=0.131 err=0.435 loss=5.65e-06
 i=1072 alpha=0.137 err=0.432 loss=4.89e-06
 i=1088 alpha=0.151 err=0.425 loss=4.23e-06
 i=1104 alpha=0.136 err=0.432 loss=3.68e-06
 i=1120 alpha=0.143 err=0.429 loss=3.16e-06
 i=1136 alpha=0.145 err=0.428 loss=2.73e-06
 i=1152 alpha=0.138 err=0.432 loss=2.37e-06
 i=1168 alpha=0.146 err=0.428 loss=2.04e-06
 i=1184 alpha=0.131 err=0.435 loss=1.74e-06
 i=1200 alpha=0.167 err=0.417 loss=1.51e-06
 i=1216 alpha=0.138 err=0.431 loss=1.29e-06
 i=1232 alpha=0.142 err=0.430 loss=1.11e-06
 i=1248 alpha=0.128 err=0.437 loss=9.52e-07
 i=1264 alpha=0.127 err=0.437 loss=8.22e-07
 i=1280 alpha=0.105 err=0.448 loss=7.13e-07
 i=1296 alpha=0.143 err=0.429 loss=6.22e-07
 i=1312 alpha=0.124 err=0.438 loss=5.40e-07
 i=1328 alpha=0.122 err=0.439 loss=4.68e-07
 i=1344 alpha=0.120 err=0.440 loss=4.05e-07
 i=1360 alpha=0.141 err=0.430 loss=3.48e-07
 i=1376 alpha=0.150 err=0.426 loss=3.01e-07
 i=1392 alpha=0.128 err=0.436 loss=2.60e-07
 i=1408 alpha=0.133 err=0.434 loss=2.24e-07
 i=1424 alpha=0.148 err=0.427 loss=1.93e-07
 i=1440 alpha=0.135 err=0.433 loss=1.68e-07
 i=1456 alpha=0.126 err=0.437 loss=1.45e-07
 i=1472 alpha=0.109 err=0.446 loss=1.25e-07
 i=1488 alpha=0.115 err=0.443 loss=1.09e-07
 i=1504 alpha=0.121 err=0.440 loss=9.42e-08
 i=1520 alpha=0.133 err=0.434 loss=8.18e-08
 i=1536 alpha=0.133 err=0.434 loss=7.04e-08
 i=1552 alpha=0.153 err=0.424 loss=6.02e-08
 i=1568 alpha=0.121 err=0.440 loss=5.25e-08
 i=1584 alpha=0.139 err=0.431 loss=4.54e-08
 i=1600 alpha=0.113 err=0.443 loss=3.94e-08
 i=1616 alpha=0.124 err=0.438 loss=3.42e-08
 i=1632 alpha=0.154 err=0.423 loss=2.96e-08
 i=1648 alpha=0.133 err=0.434 loss=2.56e-08
 i=1664 alpha=0.124 err=0.438 loss=2.18e-08
 i=1680 alpha=0.144 err=0.428 loss=1.87e-08
 i=1696 alpha=0.129 err=0.436 loss=1.63e-08
 i=1712 alpha=0.125 err=0.438 loss=1.42e-08
 i=1728 alpha=0.116 err=0.442 loss=1.22e-08
 i=1744 alpha=0.134 err=0.433 loss=1.06e-08
 i=1760 alpha=0.131 err=0.435 loss=9.15e-09
 i=1776 alpha=0.129 err=0.436 loss=7.86e-09
 i=1792 alpha=0.129 err=0.436 loss=6.84e-09
 i=1808 alpha=0.144 err=0.429 loss=5.95e-09
 i=1824 alpha=0.138 err=0.431 loss=5.15e-09
 i=1840 alpha=0.121 err=0.440 loss=4.48e-09
 i=1856 alpha=0.115 err=0.443 loss=3.86e-09
 i=1872 alpha=0.129 err=0.436 loss=3.33e-09
 i=1888 alpha=0.123 err=0.439 loss=2.88e-09
 i=1904 alpha=0.147 err=0.427 loss=2.48e-09
 i=1920 alpha=0.153 err=0.424 loss=2.13e-09
 i=1936 alpha=0.147 err=0.427 loss=1.83e-09
 i=1952 alpha=0.135 err=0.433 loss=1.59e-09
 i=1968 alpha=0.157 err=0.422 loss=1.38e-09
 i=1984 alpha=0.116 err=0.442 loss=1.19e-09
 i=2000 alpha=0.128 err=0.436 loss=1.03e-09
 i=2016 alpha=0.148 err=0.426 loss=8.93e-10
 i=2032 alpha=0.131 err=0.435 loss=7.78e-10
 i=2048 alpha=0.142 err=0.430 loss=6.71e-10
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=42.2s).
Done training stage 3 (time=135s).
---------------------------------------------------------------------------
Training stage 4
Sampled 1114 windows from 1000 images.
Done sampling windows (time=87s).
Extracting features... done (time=0s).
Training AdaBoost: nWeak=4096 nFtrs=1920 pos=33480 neg=30000
 i=  16 alpha=0.242 err=0.381 loss=3.47e-01
 i=  32 alpha=0.194 err=0.404 loss=2.33e-01
 i=  48 alpha=0.198 err=0.402 loss=1.73e-01
 i=  64 alpha=0.184 err=0.409 loss=1.36e-01
 i=  80 alpha=0.161 err=0.420 loss=1.09e-01
 i=  96 alpha=0.169 err=0.416 loss=8.89e-02
 i= 112 alpha=0.175 err=0.413 loss=7.34e-02
 i= 128 alpha=0.151 err=0.425 loss=6.16e-02
 i= 144 alpha=0.156 err=0.423 loss=5.20e-02
 i= 160 alpha=0.163 err=0.419 loss=4.32e-02
 i= 176 alpha=0.144 err=0.428 loss=3.68e-02
 i= 192 alpha=0.159 err=0.421 loss=3.11e-02
 i= 208 alpha=0.133 err=0.434 loss=2.65e-02
 i= 224 alpha=0.131 err=0.435 loss=2.28e-02
 i= 240 alpha=0.136 err=0.433 loss=1.94e-02
 i= 256 alpha=0.138 err=0.431 loss=1.67e-02
 i= 272 alpha=0.158 err=0.422 loss=1.43e-02
 i= 288 alpha=0.148 err=0.426 loss=1.23e-02
 i= 304 alpha=0.125 err=0.438 loss=1.06e-02
 i= 320 alpha=0.143 err=0.429 loss=9.16e-03
 i= 336 alpha=0.139 err=0.431 loss=7.96e-03
 i= 352 alpha=0.140 err=0.430 loss=6.94e-03
 i= 368 alpha=0.128 err=0.436 loss=6.03e-03
 i= 384 alpha=0.128 err=0.436 loss=5.23e-03
 i= 400 alpha=0.125 err=0.438 loss=4.51e-03
 i= 416 alpha=0.146 err=0.427 loss=3.88e-03
 i= 432 alpha=0.147 err=0.427 loss=3.31e-03
 i= 448 alpha=0.117 err=0.442 loss=2.85e-03
 i= 464 alpha=0.155 err=0.423 loss=2.47e-03
 i= 480 alpha=0.135 err=0.433 loss=2.14e-03
 i= 496 alpha=0.132 err=0.434 loss=1.87e-03
 i= 512 alpha=0.130 err=0.436 loss=1.63e-03
 i= 528 alpha=0.138 err=0.431 loss=1.43e-03
 i= 544 alpha=0.134 err=0.433 loss=1.25e-03
 i= 560 alpha=0.133 err=0.434 loss=1.09e-03
 i= 576 alpha=0.122 err=0.439 loss=9.57e-04
 i= 592 alpha=0.118 err=0.441 loss=8.31e-04
 i= 608 alpha=0.124 err=0.439 loss=7.34e-04
 i= 624 alpha=0.140 err=0.431 loss=6.33e-04
 i= 640 alpha=0.129 err=0.436 loss=5.52e-04
 i= 656 alpha=0.123 err=0.439 loss=4.85e-04
 i= 672 alpha=0.133 err=0.434 loss=4.25e-04
 i= 688 alpha=0.136 err=0.432 loss=3.67e-04
 i= 704 alpha=0.134 err=0.434 loss=3.20e-04
 i= 720 alpha=0.128 err=0.436 loss=2.81e-04
 i= 736 alpha=0.126 err=0.437 loss=2.46e-04
 i= 752 alpha=0.147 err=0.427 loss=2.15e-04
 i= 768 alpha=0.113 err=0.444 loss=1.86e-04
 i= 784 alpha=0.110 err=0.445 loss=1.64e-04
 i= 800 alpha=0.147 err=0.427 loss=1.42e-04
 i= 816 alpha=0.117 err=0.442 loss=1.25e-04
 i= 832 alpha=0.117 err=0.442 loss=1.09e-04
 i= 848 alpha=0.137 err=0.432 loss=9.45e-05
 i= 864 alpha=0.130 err=0.435 loss=8.24e-05
 i= 880 alpha=0.127 err=0.437 loss=7.21e-05
 i= 896 alpha=0.136 err=0.432 loss=6.28e-05
 i= 912 alpha=0.145 err=0.428 loss=5.46e-05
 i= 928 alpha=0.112 err=0.444 loss=4.79e-05
 i= 944 alpha=0.130 err=0.435 loss=4.19e-05
 i= 960 alpha=0.133 err=0.434 loss=3.66e-05
 i= 976 alpha=0.127 err=0.437 loss=3.20e-05
 i= 992 alpha=0.123 err=0.439 loss=2.79e-05
 i=1008 alpha=0.133 err=0.434 loss=2.46e-05
 i=1024 alpha=0.129 err=0.436 loss=2.16e-05
 i=1040 alpha=0.126 err=0.437 loss=1.89e-05
 i=1056 alpha=0.147 err=0.427 loss=1.63e-05
 i=1072 alpha=0.127 err=0.437 loss=1.42e-05
 i=1088 alpha=0.131 err=0.435 loss=1.24e-05
 i=1104 alpha=0.148 err=0.427 loss=1.08e-05
 i=1120 alpha=0.143 err=0.429 loss=9.41e-06
 i=1136 alpha=0.126 err=0.437 loss=8.23e-06
 i=1152 alpha=0.124 err=0.438 loss=7.15e-06
 i=1168 alpha=0.131 err=0.435 loss=6.31e-06
 i=1184 alpha=0.114 err=0.443 loss=5.53e-06
 i=1200 alpha=0.138 err=0.431 loss=4.84e-06
 i=1216 alpha=0.138 err=0.432 loss=4.23e-06
 i=1232 alpha=0.110 err=0.445 loss=3.70e-06
 i=1248 alpha=0.127 err=0.437 loss=3.22e-06
 i=1264 alpha=0.142 err=0.430 loss=2.81e-06
 i=1280 alpha=0.129 err=0.436 loss=2.43e-06
 i=1296 alpha=0.134 err=0.434 loss=2.12e-06
 i=1312 alpha=0.135 err=0.433 loss=1.84e-06
 i=1328 alpha=0.127 err=0.437 loss=1.60e-06
 i=1344 alpha=0.143 err=0.429 loss=1.39e-06
 i=1360 alpha=0.092 err=0.454 loss=1.23e-06
 i=1376 alpha=0.141 err=0.430 loss=1.07e-06
 i=1392 alpha=0.128 err=0.436 loss=9.39e-07
 i=1408 alpha=0.121 err=0.440 loss=8.20e-07
 i=1424 alpha=0.126 err=0.437 loss=7.16e-07
 i=1440 alpha=0.130 err=0.435 loss=6.27e-07
 i=1456 alpha=0.132 err=0.434 loss=5.52e-07
 i=1472 alpha=0.117 err=0.442 loss=4.77e-07
 i=1488 alpha=0.140 err=0.430 loss=4.15e-07
 i=1504 alpha=0.125 err=0.438 loss=3.68e-07
 i=1520 alpha=0.116 err=0.442 loss=3.26e-07
 i=1536 alpha=0.133 err=0.434 loss=2.82e-07
 i=1552 alpha=0.131 err=0.435 loss=2.47e-07
 i=1568 alpha=0.138 err=0.431 loss=2.15e-07
 i=1584 alpha=0.123 err=0.439 loss=1.88e-07
 i=1600 alpha=0.135 err=0.433 loss=1.64e-07
 i=1616 alpha=0.141 err=0.430 loss=1.43e-07
 i=1632 alpha=0.136 err=0.433 loss=1.25e-07
 i=1648 alpha=0.123 err=0.439 loss=1.09e-07
 i=1664 alpha=0.124 err=0.438 loss=9.52e-08
 i=1680 alpha=0.131 err=0.435 loss=8.35e-08
 i=1696 alpha=0.138 err=0.431 loss=7.23e-08
 i=1712 alpha=0.137 err=0.432 loss=6.27e-08
 i=1728 alpha=0.132 err=0.434 loss=5.41e-08
 i=1744 alpha=0.149 err=0.426 loss=4.74e-08
 i=1760 alpha=0.132 err=0.435 loss=4.16e-08
 i=1776 alpha=0.120 err=0.440 loss=3.63e-08
 i=1792 alpha=0.119 err=0.441 loss=3.18e-08
 i=1808 alpha=0.138 err=0.431 loss=2.81e-08
 i=1824 alpha=0.119 err=0.441 loss=2.45e-08
 i=1840 alpha=0.126 err=0.437 loss=2.16e-08
 i=1856 alpha=0.122 err=0.440 loss=1.88e-08
 i=1872 alpha=0.140 err=0.431 loss=1.64e-08
 i=1888 alpha=0.111 err=0.445 loss=1.43e-08
 i=1904 alpha=0.122 err=0.439 loss=1.25e-08
 i=1920 alpha=0.122 err=0.439 loss=1.09e-08
 i=1936 alpha=0.136 err=0.432 loss=9.49e-09
 i=1952 alpha=0.134 err=0.434 loss=8.33e-09
 i=1968 alpha=0.121 err=0.440 loss=7.33e-09
 i=1984 alpha=0.141 err=0.430 loss=6.37e-09
 i=2000 alpha=0.116 err=0.442 loss=5.56e-09
 i=2016 alpha=0.126 err=0.437 loss=4.83e-09
 i=2032 alpha=0.130 err=0.435 loss=4.24e-09
 i=2048 alpha=0.129 err=0.436 loss=3.71e-09
 i=2064 alpha=0.130 err=0.435 loss=3.21e-09
 i=2080 alpha=0.124 err=0.438 loss=2.80e-09
 i=2096 alpha=0.146 err=0.428 loss=2.41e-09
 i=2112 alpha=0.138 err=0.431 loss=2.10e-09
 i=2128 alpha=0.132 err=0.434 loss=1.83e-09
 i=2144 alpha=0.136 err=0.432 loss=1.61e-09
 i=2160 alpha=0.154 err=0.424 loss=1.41e-09
 i=2176 alpha=0.129 err=0.436 loss=1.23e-09
 i=2192 alpha=0.103 err=0.449 loss=1.09e-09
 i=2208 alpha=0.118 err=0.441 loss=9.52e-10
 i=2224 alpha=0.122 err=0.439 loss=8.31e-10
 i=2240 alpha=0.120 err=0.440 loss=7.33e-10
 i=2256 alpha=0.130 err=0.435 loss=6.39e-10
 i=2272 alpha=0.153 err=0.424 loss=5.62e-10
 i=2288 alpha=0.142 err=0.429 loss=4.89e-10
 i=2304 alpha=0.128 err=0.436 loss=4.25e-10
 i=2320 alpha=0.133 err=0.434 loss=3.71e-10
 i=2336 alpha=0.119 err=0.441 loss=3.22e-10
 i=2352 alpha=0.130 err=0.435 loss=2.82e-10
 i=2368 alpha=0.118 err=0.441 loss=2.47e-10
 i=2384 alpha=0.125 err=0.438 loss=2.14e-10
 i=2400 alpha=0.130 err=0.436 loss=1.87e-10
 i=2416 alpha=0.125 err=0.438 loss=1.65e-10
 i=2432 alpha=0.139 err=0.431 loss=1.44e-10
 i=2448 alpha=0.147 err=0.427 loss=1.26e-10
 i=2464 alpha=0.145 err=0.428 loss=1.10e-10
 i=2480 alpha=0.127 err=0.437 loss=9.62e-11
 i=2496 alpha=0.119 err=0.441 loss=8.44e-11
 i=2512 alpha=0.122 err=0.439 loss=7.52e-11
 i=2528 alpha=0.096 err=0.452 loss=6.61e-11
 i=2544 alpha=0.122 err=0.439 loss=5.78e-11
 i=2560 alpha=0.112 err=0.444 loss=5.06e-11
 i=2576 alpha=0.132 err=0.435 loss=4.39e-11
 i=2592 alpha=0.126 err=0.438 loss=3.85e-11
 i=2608 alpha=0.132 err=0.435 loss=3.35e-11
 i=2624 alpha=0.135 err=0.433 loss=2.92e-11
 i=2640 alpha=0.113 err=0.444 loss=2.56e-11
 i=2656 alpha=0.135 err=0.433 loss=2.24e-11
 i=2672 alpha=0.128 err=0.436 loss=1.95e-11
 i=2688 alpha=0.142 err=0.429 loss=1.69e-11
 i=2704 alpha=0.120 err=0.440 loss=1.48e-11
 i=2720 alpha=0.128 err=0.436 loss=1.28e-11
 i=2736 alpha=0.131 err=0.435 loss=1.13e-11
 i=2752 alpha=0.144 err=0.428 loss=9.95e-12
 i=2768 alpha=0.126 err=0.438 loss=8.70e-12
 i=2784 alpha=0.109 err=0.446 loss=7.60e-12
 i=2800 alpha=0.146 err=0.428 loss=6.62e-12
 i=2816 alpha=0.151 err=0.425 loss=5.81e-12
 i=2832 alpha=0.144 err=0.429 loss=5.10e-12
 i=2848 alpha=0.124 err=0.438 loss=4.52e-12
 i=2864 alpha=0.128 err=0.436 loss=3.98e-12
 i=2880 alpha=0.128 err=0.437 loss=3.46e-12
 i=2896 alpha=0.130 err=0.435 loss=3.06e-12
 i=2912 alpha=0.136 err=0.433 loss=2.66e-12
 i=2928 alpha=0.140 err=0.431 loss=2.31e-12
 i=2944 alpha=0.114 err=0.443 loss=2.04e-12
 i=2960 alpha=0.131 err=0.435 loss=1.79e-12
 i=2976 alpha=0.137 err=0.432 loss=1.57e-12
 i=2992 alpha=0.135 err=0.433 loss=1.38e-12
 i=3008 alpha=0.122 err=0.439 loss=1.20e-12
 i=3024 alpha=0.137 err=0.432 loss=1.05e-12
 i=3040 alpha=0.122 err=0.439 loss=9.23e-13
 i=3056 alpha=0.119 err=0.441 loss=8.15e-13
 i=3072 alpha=0.142 err=0.429 loss=7.08e-13
 i=3088 alpha=0.132 err=0.435 loss=6.21e-13
 i=3104 alpha=0.146 err=0.428 loss=5.39e-13
 i=3120 alpha=0.132 err=0.435 loss=4.72e-13
 i=3136 alpha=0.122 err=0.440 loss=4.10e-13
 i=3152 alpha=0.138 err=0.432 loss=3.59e-13
 i=3168 alpha=0.117 err=0.442 loss=3.15e-13
 i=3184 alpha=0.127 err=0.437 loss=2.72e-13
 i=3200 alpha=0.106 err=0.447 loss=2.40e-13
 i=3216 alpha=0.128 err=0.437 loss=2.10e-13
 i=3232 alpha=0.134 err=0.433 loss=1.84e-13
 i=3248 alpha=0.144 err=0.428 loss=1.61e-13
 i=3264 alpha=0.135 err=0.433 loss=1.40e-13
 i=3280 alpha=0.115 err=0.443 loss=1.23e-13
 i=3296 alpha=0.126 err=0.437 loss=1.08e-13
 i=3312 alpha=0.133 err=0.434 loss=9.45e-14
 i=3328 alpha=0.115 err=0.443 loss=8.30e-14
 i=3344 alpha=0.144 err=0.429 loss=7.17e-14
 i=3360 alpha=0.136 err=0.433 loss=6.32e-14
 i=3376 alpha=0.130 err=0.436 loss=5.53e-14
 i=3392 alpha=0.129 err=0.436 loss=4.84e-14
 i=3408 alpha=0.128 err=0.436 loss=4.21e-14
 i=3424 alpha=0.139 err=0.431 loss=3.67e-14
 i=3440 alpha=0.128 err=0.436 loss=3.22e-14
 i=3456 alpha=0.130 err=0.435 loss=2.83e-14
 i=3472 alpha=0.129 err=0.436 loss=2.49e-14
 i=3488 alpha=0.122 err=0.439 loss=2.17e-14
 i=3504 alpha=0.145 err=0.428 loss=1.87e-14
 i=3520 alpha=0.132 err=0.434 loss=1.64e-14
 i=3536 alpha=0.127 err=0.437 loss=1.44e-14
 i=3552 alpha=0.125 err=0.438 loss=1.26e-14
 i=3568 alpha=0.113 err=0.444 loss=1.11e-14
 i=3584 alpha=0.128 err=0.436 loss=9.77e-15
 i=3600 alpha=0.142 err=0.429 loss=8.57e-15
 i=3616 alpha=0.122 err=0.439 loss=7.51e-15
 i=3632 alpha=0.117 err=0.442 loss=6.49e-15
 i=3648 alpha=0.139 err=0.431 loss=5.67e-15
 i=3664 alpha=0.128 err=0.436 loss=4.97e-15
 i=3680 alpha=0.126 err=0.437 loss=4.37e-15
 i=3696 alpha=0.144 err=0.428 loss=3.81e-15
 i=3712 alpha=0.114 err=0.443 loss=3.33e-15
 i=3728 alpha=0.127 err=0.437 loss=2.92e-15
 i=3744 alpha=0.107 err=0.447 loss=2.55e-15
 i=3760 alpha=0.107 err=0.447 loss=2.26e-15
 i=3776 alpha=0.113 err=0.444 loss=1.98e-15
 i=3792 alpha=0.133 err=0.434 loss=1.74e-15
 i=3808 alpha=0.131 err=0.435 loss=1.52e-15
 i=3824 alpha=0.126 err=0.437 loss=1.34e-15
 i=3840 alpha=0.127 err=0.437 loss=1.17e-15
 i=3856 alpha=0.113 err=0.444 loss=1.03e-15
 i=3872 alpha=0.129 err=0.436 loss=9.06e-16
 i=3888 alpha=0.124 err=0.438 loss=7.91e-16
 i=3904 alpha=0.126 err=0.438 loss=6.88e-16
 i=3920 alpha=0.139 err=0.431 loss=6.04e-16
 i=3936 alpha=0.149 err=0.426 loss=5.26e-16
 i=3952 alpha=0.131 err=0.435 loss=4.62e-16
 i=3968 alpha=0.135 err=0.433 loss=4.06e-16
 i=3984 alpha=0.151 err=0.425 loss=3.58e-16
 i=4000 alpha=0.136 err=0.433 loss=3.13e-16
 i=4016 alpha=0.143 err=0.429 loss=2.70e-16
 i=4032 alpha=0.129 err=0.436 loss=2.35e-16
 i=4048 alpha=0.137 err=0.432 loss=2.09e-16
 i=4064 alpha=0.123 err=0.439 loss=1.84e-16
 i=4080 alpha=0.134 err=0.433 loss=1.60e-16
 i=4096 alpha=0.118 err=0.441 loss=1.41e-16
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=84.6s).
Done training stage 4 (time=172s).
---------------------------------------------------------------------------
Done training (time=1717s).
